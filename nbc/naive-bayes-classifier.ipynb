{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "da1562da-a879-449f-980a-de5a47c533bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3d0bae07-1cb9-4239-807d-bf77b305bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    '''\n",
    "    Input: \n",
    "        path: str\n",
    "              data path\n",
    "    Output:\n",
    "        X: list, shape=(n,)\n",
    "           list of messages\n",
    "        Y: ndarray, shape=(n,)\n",
    "           labels\n",
    "    '''\n",
    "    data = pd.read_csv(path, sep='\\t', header=None)\n",
    "    \n",
    "    X = data[1].str.lower().tolist()\n",
    "    Y = (data[0] == 'spam').to_numpy() * 1\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "72945a78-3acf-4c7c-b347-ff9748f8b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Setting up parameters\n",
    "        '''\n",
    "        self.phi = None\n",
    "        self.phiy1 = None\n",
    "        self.phiy0 = None\n",
    "        self.vocabulary = None\n",
    "        \n",
    "    def make_vocabulary(self, X):\n",
    "        '''\n",
    "        Input: \n",
    "            X: list, shape(n,)\n",
    "               list of messages\n",
    "        Output: \n",
    "            vocabulary: dictionary, shape(d,2)\n",
    "                        vocabulary of data\n",
    "        '''\n",
    "        n = len(X_train)\n",
    "        dict_pos = 0\n",
    "        vocabulary_word_count = {}\n",
    "        vocabulary = {}\n",
    "\n",
    "        for message in X:\n",
    "            message_word_count = collections.Counter(message.split(' '))\n",
    "            for word in message_word_count:\n",
    "                if word in vocabulary_word_count:\n",
    "                    vocabulary_word_count[word] += 1\n",
    "                else:\n",
    "                    vocabulary_word_count[word] = 1\n",
    "\n",
    "        for word in vocabulary_word_count:\n",
    "            if vocabulary_word_count[word] >= 5:\n",
    "                vocabulary[word] = dict_pos\n",
    "                dict_pos += 1\n",
    "    \n",
    "        return dict(sorted(vocabulary.items(), key = lambda x: x[1]))\n",
    "\n",
    "    def to_vector(self, X, vocabulary):\n",
    "        '''\n",
    "        Input: \n",
    "            X: list, shape(n,)\n",
    "               list of messages\n",
    "            vocabulary: dictionary, shape(d,2)\n",
    "                        vocabulary of data\n",
    "        Output:\n",
    "            X_transformed: ndarray, shape(n,d)\n",
    "                           messages represented in vector form\n",
    "        '''\n",
    "        n = len(X)\n",
    "        d = len(vocabulary)\n",
    "        X_transformed = np.zeros((n,d))\n",
    "\n",
    "        for i, message in enumerate(X):\n",
    "            word_dict = collections.Counter(message.split(' '))\n",
    "            for word in word_dict:\n",
    "                if word in vocabulary:\n",
    "                    X_transformed[i, vocabulary[word]] = 1\n",
    "\n",
    "        return X_transformed\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        '''\n",
    "        Input: \n",
    "            X: list, shape(n,)\n",
    "               list of messages\n",
    "            Y: ndarray, shape(n,)\n",
    "               labels\n",
    "        Output: self\n",
    "        '''\n",
    "        \n",
    "        vocabulary = self.make_vocabulary(X)\n",
    "        X_transformed = self.to_vector(X, vocabulary)\n",
    "        \n",
    "        n, d = X_transformed.shape\n",
    "        \n",
    "        spam_count = np.sum(Y)\n",
    "        \n",
    "        self.phi = spam_count / n\n",
    "        self.phiy1 = (1 + np.sum(X_transformed[Y == 1], axis=0)) / (2 + spam_count)\n",
    "        self.phiy0 = (1 + np.sum(X_transformed[Y == 0], axis=0)) / (2 + n - spam_count)\n",
    "        self.vocabulary = vocabulary\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, threshold):\n",
    "        '''\n",
    "        Input:\n",
    "            X: list, shape(n,)\n",
    "               list of messages\n",
    "            threshold: float, 0 <= threshold <= 1\n",
    "        Output:\n",
    "            Y: ndarray, shape(n,)\n",
    "               prediction, p(y=1|x)\n",
    "        '''\n",
    "        if type(X) != type([]):\n",
    "            X_transformed = to_vector([X], self.vocabulary)\n",
    "        else:\n",
    "            X_transformed = to_vector(X, self.vocabulary)\n",
    "            \n",
    "        n, d = X_transformed.shape\n",
    "        \n",
    "    \n",
    "        p_x_given_y1_matrix = np.outer(np.ones(n), nb.phiy1)\n",
    "        p_x_given_y0_matrix = np.outer(np.ones(n), nb.phiy0)\n",
    "        \n",
    "        p_x_given_y1_matrix[X_transformed == 0] = (1 - np.outer(np.ones(n), nb.phiy1))[X_transformed == 0]\n",
    "        p_x_given_y0_matrix[X_transformed == 0] = (1 - np.outer(np.ones(n), nb.phiy0))[X_transformed == 0]\n",
    "        \n",
    "        p_x_and_y1 = np.sum(np.log(p_x_given_y1_matrix), axis=1) + np.log(nb.phi)\n",
    "        p_x_and_y0 = np.sum(np.log(p_x_given_y0_matrix), axis=1) + np.log(1 - nb.phi)\n",
    "        \n",
    "        px = np.exp(p_x_and_y1) + np.exp(p_x_and_y0)\n",
    "        \n",
    "        Y = np.exp(p_x_and_y1) / px\n",
    "    \n",
    "        spam_index = np.array(Y > threshold)\n",
    "        Y[spam_index] = 1\n",
    "        Y[~spam_index] = 0\n",
    "        \n",
    "        return Y\n",
    "    \n",
    "    def evaluate(self, Y_predict, Y_true):\n",
    "        '''\n",
    "        Input: \n",
    "            Y_predict: ndarray, shape(n,)\n",
    "            Y_true: ndarray, shape(n,)\n",
    "        Output:\n",
    "            score: float, 0 <= score <= 1\n",
    "        '''\n",
    "        return np.sum(Y_predict == Y_true) / len(Y_true)\n",
    "    \n",
    "    def top_spam_words(self, k):\n",
    "        '''\n",
    "        Input:\n",
    "            k: int, 0 <= k\n",
    "        Output:\n",
    "            Top k spam words: list\n",
    "        '''\n",
    "        arg_spam_word_sorted = np.argsort(np.log(nb.phiy1/nb.phiy0))[::-1]\n",
    "        inv_vocabulary = {value: key for key, value in nb.vocabulary.items()}\n",
    "        \n",
    "        return [inv_vocabulary[arg_spam_word_sorted[i]] for i in range(k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "aca4b678-3448-4d4b-987d-a7e56582b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_data('spam_train.tsv')\n",
    "X_val, Y_val = read_data('spam_val.tsv')\n",
    "X_test, Y_test = read_data('spam_test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d19fe19a-1d5f-489d-9624-7273e313484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NB().fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "25406c73-5ee4-44e3-b46b-49c0b951c705",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9820466786355476\n"
     ]
    }
   ],
   "source": [
    "prediction = nb.predict(X_val, .6)\n",
    "score = nb.evaluate(prediction, Y_val)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f30d8ab3-45d7-42ee-b5f5-0834521cf648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.982078853046595\n"
     ]
    }
   ],
   "source": [
    "prediction = nb.predict(X_test, .6)\n",
    "score = nb.evaluate(prediction, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "5862f683-4377-4afa-a8b1-286e954ab8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['claim',\n",
       " 'won',\n",
       " 'prize',\n",
       " 'urgent!',\n",
       " 'awarded',\n",
       " 'tone',\n",
       " 'Â£1000',\n",
       " 'guaranteed',\n",
       " '4*',\n",
       " '150ppm']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.top_spam_words(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72657c88-37ad-4c40-b718-542f155e6cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
